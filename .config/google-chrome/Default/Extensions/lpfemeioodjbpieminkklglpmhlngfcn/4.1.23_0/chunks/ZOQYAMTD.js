import{a as L,c as I}from"./OUNRME46.js";import{a as N,b as v,e as E,g as C}from"./SKM5Z6ZR.js";import{a as T,b as A,c as k,d as z,e as M}from"./KSSOAXI3.js";import"./USLLVG5P.js";import{f as U}from"./UTGLRY7A.js";var w=U(L(),1);var P=class extends C{constructor(e){super(e)}async generate(e,t,n){let r=[],a=[],i;Array.isArray(t)?i={stop:t}:t?.timeout&&!t.signal?i={...t,signal:AbortSignal.timeout(t.timeout)}:i=t??{};let c=await E.configure(n,this.callbacks,{verbose:this.verbose}),d={invocation_params:this?.invocationParams()},u=await c?.handleChatModelStart({name:this._llmType()},e,void 0,void 0,d);try{let h=await Promise.all(e.map(s=>this._generate(s,i,u)));for(let s of h)s.llmOutput&&a.push(s.llmOutput),r.push(s.generations)}catch(h){throw await u?.handleLLMError(h),h}let l={generations:r,llmOutput:a.length?this._combineLLMOutput?.(...a):void 0};return await u?.handleLLMEnd(l),Object.defineProperty(l,T,{value:u?{runId:u?.runId}:void 0,configurable:!0}),l}invocationParams(){return{}}_modelType(){return"base_chat_model"}async generatePrompt(e,t,n){let r=e.map(a=>a.toChatMessages());return this.generate(r,t,n)}async call(e,t,n){return(await this.generate([e],t,n)).generations[0][0].message}async callPrompt(e,t,n){let r=e.toChatMessages();return this.call(r,t,n)}async predictMessages(e,t,n){return this.call(e,t,n)}async predict(e,t,n){let r=new A(e);return(await this.call([r],t,n)).text}};function x(m){switch(m){case"system":return"system";case"ai":return"assistant";case"human":return"user";default:throw new Error(`Unknown message type: ${m}`)}}function R(m,e){switch(m){case"user":return new A(e);case"assistant":return new k(e);case"system":return new z(e);default:return new M(e,m??"unknown")}}var j=class extends P{get callKeys(){return["stop","signal","timeout","options"]}constructor(e,t){super(e??{}),Object.defineProperty(this,"temperature",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"topP",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"frequencyPenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"presencePenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"n",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"logitBias",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"modelName",{enumerable:!0,configurable:!0,writable:!0,value:"gpt-3.5-turbo"}),Object.defineProperty(this,"modelKwargs",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"stop",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"timeout",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"streaming",{enumerable:!0,configurable:!0,writable:!0,value:!1}),Object.defineProperty(this,"maxTokens",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"azureOpenAIApiVersion",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"azureOpenAIApiKey",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"azureOpenAIApiInstanceName",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"azureOpenAIApiDeploymentName",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"client",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"clientConfig",{enumerable:!0,configurable:!0,writable:!0,value:void 0});let n=e?.openAIApiKey??(typeof process<"u"?process.env?.OPENAI_API_KEY:void 0),r=e?.azureOpenAIApiKey??(typeof process<"u"?process.env?.AZURE_OPENAI_API_KEY:void 0);if(!r&&!n)throw new Error("(Azure) OpenAI API key not found");let a=e?.azureOpenAIApiInstanceName??(typeof process<"u"?process.env?.AZURE_OPENAI_API_INSTANCE_NAME:void 0),i=e?.azureOpenAIApiDeploymentName??(typeof process<"u"?process.env?.AZURE_OPENAI_API_DEPLOYMENT_NAME:void 0),c=e?.azureOpenAIApiVersion??(typeof process<"u"?process.env?.AZURE_OPENAI_API_VERSION:void 0);if(this.modelName=e?.modelName??this.modelName,this.modelKwargs=e?.modelKwargs??{},this.timeout=e?.timeout,this.temperature=e?.temperature??this.temperature,this.topP=e?.topP??this.topP,this.frequencyPenalty=e?.frequencyPenalty??this.frequencyPenalty,this.presencePenalty=e?.presencePenalty??this.presencePenalty,this.maxTokens=e?.maxTokens,this.n=e?.n??this.n,this.logitBias=e?.logitBias,this.stop=e?.stop,this.streaming=e?.streaming??!1,this.azureOpenAIApiVersion=c,this.azureOpenAIApiKey=r,this.azureOpenAIApiInstanceName=a,this.azureOpenAIApiDeploymentName=i,this.streaming&&this.n>1)throw new Error("Cannot stream results when n > 1");if(this.azureOpenAIApiKey){if(!this.azureOpenAIApiInstanceName)throw new Error("Azure OpenAI API instance name not found");if(!this.azureOpenAIApiDeploymentName)throw new Error("Azure OpenAI API deployment name not found");if(!this.azureOpenAIApiVersion)throw new Error("Azure OpenAI API version not found")}this.clientConfig={apiKey:n,...t}}invocationParams(){return{model:this.modelName,temperature:this.temperature,top_p:this.topP,frequency_penalty:this.frequencyPenalty,presence_penalty:this.presencePenalty,max_tokens:this.maxTokens===-1?void 0:this.maxTokens,n:this.n,logit_bias:this.logitBias,stop:this.stop,stream:this.streaming,...this.modelKwargs}}_identifyingParams(){return{model_name:this.modelName,...this.invocationParams(),...this.clientConfig}}identifyingParams(){return this._identifyingParams()}async _generate(e,t,n){let r={};if(this.stop&&t?.stop)throw new Error("Stop found in input and default params");let a=this.invocationParams();a.stop=t?.stop??a.stop;let i=e.map(s=>({role:x(s._getType()),content:s.text,name:s.name})),c=a.stream?await new Promise((s,O)=>{let p,_=!1,y=!1;this.completionWithRetry({...a,messages:i},{signal:t?.signal,...t?.options,adapter:I,responseType:"stream",onmessage:b=>{if(b.data?.trim?.()==="[DONE]"){if(y)return;y=!0,s(p)}else{let f=JSON.parse(b.data);p||(p={id:f.id,object:f.object,created:f.created,model:f.model,choices:[]});for(let o of f.choices)if(o!=null){let g=p.choices.find(K=>K.index===o.index);g||(g={index:o.index,finish_reason:o.finish_reason??void 0},p.choices[o.index]=g),g.message||(g.message={role:o.delta?.role,content:o.delta?.content??""}),g.message.content+=o.delta?.content??"",n?.handleLLMNewToken(o.delta?.content??"")}!y&&f.choices.every(o=>o.finish_reason!=null)&&(y=!0,s(p))}}}).catch(b=>{_||(_=!0,O(b))})}):await this.completionWithRetry({...a,messages:i},{signal:t?.signal,...t?.options}),{completion_tokens:d,prompt_tokens:u,total_tokens:l}=c.usage??{};d&&(r.completionTokens=(r.completionTokens??0)+d),u&&(r.promptTokens=(r.promptTokens??0)+u),l&&(r.totalTokens=(r.totalTokens??0)+l);let h=[];for(let s of c.choices){let O=s.message?.role??void 0,p=s.message?.content??"";h.push({text:p,message:R(O,p)})}return{generations:h,llmOutput:{tokenUsage:r}}}async getNumTokensFromMessages(e){let t=0,n=0,r=0;v(this.modelName)==="gpt-3.5-turbo"?(n=4,r=-1):v(this.modelName).startsWith("gpt-4")&&(n=3,r=1);let a=await Promise.all(e.map(async i=>{let c=await this.getNumTokens(i.text),d=await this.getNumTokens(x(i._getType())),u=i.name!==void 0?r+await this.getNumTokens(i.name):0,l=c+n+d+u;return t+=l,l}));return t+=3,{totalCount:t,countPerMessage:a}}async completionWithRetry(e,t){if(!this.client){let r=this.azureOpenAIApiKey?`https://${this.azureOpenAIApiInstanceName}.openai.azure.com/openai/deployments/${this.azureOpenAIApiDeploymentName}`:this.clientConfig.basePath,a=new w.Configuration({...this.clientConfig,basePath:r,baseOptions:{timeout:this.timeout,...this.clientConfig.baseOptions}});this.client=new w.OpenAIApi(a)}let n={adapter:N()?void 0:I,...this.clientConfig.baseOptions,...t};return this.azureOpenAIApiKey&&(n.headers={"api-key":this.azureOpenAIApiKey,...n.headers},n.params={"api-version":this.azureOpenAIApiVersion,...n.params}),this.caller.call(this.client.createChatCompletion.bind(this.client),e,n).then(r=>r.data)}_llmType(){return"openai"}_combineLLMOutput(...e){return e.reduce((t,n)=>(n&&n.tokenUsage&&(t.tokenUsage.completionTokens+=n.tokenUsage.completionTokens??0,t.tokenUsage.promptTokens+=n.tokenUsage.promptTokens??0,t.tokenUsage.totalTokens+=n.tokenUsage.totalTokens??0),t),{tokenUsage:{completionTokens:0,promptTokens:0,totalTokens:0}})}};export{j as ChatOpenAI};
